# robots.txt for routerkit.com
# Allow all search engines to crawl all pages

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://routerkit.com/sitemap.xml

# Crawl-delay (optional, adjust if needed)
# Crawl-delay: 1

# Block access to admin or sensitive paths if any
# Disallow: /admin/
# Disallow: /api/
